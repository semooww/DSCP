{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 20:48:35.868892: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-23 20:48:36.316060: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-23 20:48:36.316086: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-23 20:48:37.560500: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-23 20:48:37.560587: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-23 20:48:37.560594: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 folder in dataset.\n",
      "\t-There are 300 images in 1_normal folder.\n",
      "\t-There are 100 images in 2_cataract folder.\n",
      "\t-There are 101 images in 2_glaucoma folder.\n",
      "\t-There are 100 images in 3_retina_disease folder.\n",
      "                                         paths  class-label\n",
      "110              ./dataset/1_normal/NL_111.png            0\n",
      "419      ./dataset/2_glaucoma/Glaucoma_020.png            2\n",
      "565  ./dataset/3_retina_disease/Retina_065.png            3\n",
      "77               ./dataset/1_normal/NL_078.png            0\n",
      "181              ./dataset/1_normal/NL_182.png            0\n",
      "284              ./dataset/1_normal/NL_285.png            0\n",
      "10               ./dataset/1_normal/NL_011.png            0\n",
      "469      ./dataset/2_glaucoma/Glaucoma_070.png            2\n",
      "78               ./dataset/1_normal/NL_079.png            0\n",
      "349      ./dataset/2_cataract/cataract_050.png            1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATASET_PATH = r\"./dataset/\"\n",
    "IMAGE_WIDTH = 256\n",
    "IMAGE_HEIGHT = 256\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "dataset_folders = []\n",
    "total = 0\n",
    "print(f\"There are {len(os.listdir(DATASET_PATH))} folder in dataset.\")\n",
    "for path in sorted(os.listdir(DATASET_PATH)):\n",
    "    print(f\"\\t-There are {len(os.listdir(DATASET_PATH + path))} images in {path} folder.\")\n",
    "    total += len(os.listdir(DATASET_PATH + path))\n",
    "    folder_path = DATASET_PATH + path\n",
    "    dataset_folders.append(folder_path)\n",
    "\n",
    "df = pd.DataFrame(0,\n",
    "                  columns=['paths',\n",
    "                           'class-label'],\n",
    "                  index=range(total))\n",
    "i = 0\n",
    "for p, path in enumerate(dataset_folders):\n",
    "    for sub_path in sorted(os.listdir(path)):\n",
    "        df.iloc[i, 0] = path + \"/\" + sub_path\n",
    "        df.iloc[i, 1] = p\n",
    "        i += 1\n",
    "print(df.sample(frac=1, random_state=SEED).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizes the histogram of images\n",
    "def normalize_histograms(img):\n",
    "    image_copy = img.copy()\n",
    "    for i in range(3):\n",
    "        imi = img[:, :, i]\n",
    "        minval = np.min(imi)\n",
    "        maxval = np.max(imi)\n",
    "        imrange = maxval - minval\n",
    "        # imi-minval will turn the color range between 0-imrange, and the scaling will stretch the range between 0-255\n",
    "        image_copy[:, :, i] = (255 / (imrange + 0.0001) * (imi - minval))\n",
    "    return image_copy\n",
    "\n",
    "\n",
    "#Cropping image to avoid from unuseful black areas\n",
    "def deleteBlackAreas(filename):\n",
    "    image_size = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "    img = cv2.imread(filename)  #read image from file\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # convert to grayscale\n",
    "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)  # turn it into a binary image\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # find contours\n",
    "    if len(contours) != 0:\n",
    "        #find the biggest area\n",
    "        cnt = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        #find the bounding rect\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "        crop = img[y:y + h, x:x + w]  # crop image\n",
    "        crop1 = cv2.cvtColor(cv2.resize(crop, image_size, interpolation=cv2.INTER_AREA),\n",
    "                             cv2.COLOR_BGR2RGB)  # resize to image_size and change color space from BGR to RGB for matplotlib\n",
    "        return crop1\n",
    "    else:\n",
    "        return cv2.resize(img, image_size, interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, mode=0):\n",
    "    # Creating dataset\n",
    "    images = {0: [], 1: []}\n",
    "    labels = {0: [], 1: []}\n",
    "    limit = len(df) - len(df) // 5\n",
    "    index = 0\n",
    "    df = df.sample(frac=1, random_state=SEED)\n",
    "    for i in range(len(df)):\n",
    "        if (i + 1) >= limit:\n",
    "            index = 1\n",
    "        filename = df.iloc[i][\"paths\"]\n",
    "        if i % 100 == 0:\n",
    "            print(f\"{i}. step---> {filename}\")\n",
    "        img = deleteBlackAreas(filename)\n",
    "        if mode == 1:\n",
    "            img = normalize_histograms(img)\n",
    "        label = df.iloc[i][\"class-label\"]\n",
    "\n",
    "        imlr = cv2.flip(img, 0)\n",
    "        imud = cv2.flip(img, 1)\n",
    "\n",
    "        #add all the images an labels\n",
    "        images[index].append(img)\n",
    "        labels[index].append(label)\n",
    "        images[index].append(imlr)\n",
    "        labels[index].append(label)\n",
    "        images[index].append(imud)\n",
    "        labels[index].append(label)\n",
    "\n",
    "        # imb=img+0.05*img # brighter image\n",
    "        # imblr=cv2.flip(imb,0)\n",
    "        # imbud=cv2.flip(imb,1)\n",
    "        # images.append(imb)\n",
    "        # labels.append(label)\n",
    "        # images.append(imblr)\n",
    "        # labels.append(label)\n",
    "        # images.append(imbud)\n",
    "        # labels.append(label)\n",
    "\n",
    "        # imd=img-0.075*img #deemer image\n",
    "        # imdlr=cv2.flip(imd,0)\n",
    "        # imdud=cv2.flip(imd,1)\n",
    "        # images[index].append(imd)\n",
    "        # labels[index].append(label)\n",
    "        # images[index].append(imdlr)\n",
    "        # labels[index].append(label)\n",
    "        # images[index].append(imdud)\n",
    "        # labels[index].append(label)\n",
    "    print(f\"{len(images[0])} train images in images dict and {len(images[1])} test images in images dict\")\n",
    "    print(f\"{len(labels[0])} train labels in labels dict and {len(labels[1])} test labels in labels dict\")\n",
    "    return np.array(images[0]), np.array(images[1]), np.array(labels[0]), np.array(labels[1])\n",
    "\n",
    "\n",
    "def split_dataset(X, Y):\n",
    "    # set aside 20% of train and test data for evaluation\n",
    "    X_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=SEED)\n",
    "    # Use the same function above for the validation set\n",
    "    X_train = np.array(X_train)\n",
    "    x_val = np.array(x_val)\n",
    "    y_train = np.array(y_train)\n",
    "    y_val = np.array(y_val)\n",
    "    print(\"X_train shape: {}\".format(X_train.shape))\n",
    "    print(\"x_val shape: {}\".format(x_val.shape))\n",
    "    print(\"y_train shape: {}\".format(y_train.reshape(-1, 1).shape))\n",
    "    print(\"y_val shape: {}\".format(y_val.reshape(-1, 1).shape))\n",
    "    return [X_train, x_val, y_train, y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. step---> ./dataset/1_normal/NL_111.png\n",
      "100. step---> ./dataset/1_normal/NL_091.png\n",
      "200. step---> ./dataset/1_normal/NL_125.png\n",
      "300. step---> ./dataset/1_normal/NL_195.png\n",
      "400. step---> ./dataset/2_glaucoma/Glaucoma_083.png\n",
      "500. step---> ./dataset/1_normal/NL_268.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating dataset and split the data\n",
    "X_train, X_test, y_train, y_test = create_dataset(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pie_sets(arrays):\n",
    "    titles = [\"Train Set\", \"Test Set\"]\n",
    "    labels = [\"Normal\", \"Cataract\", \"Glaucoma\", \"Retina Disease\"]\n",
    "    fig = plt.figure(figsize=(9, 5))\n",
    "    plt.title(\"Distribution\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.grid(False)\n",
    "    for i in range(2):\n",
    "        fig.add_subplot(1, 2, i + 1)\n",
    "        arr = []\n",
    "        for j in range(4):\n",
    "            arr.append((arrays[i] == j).sum())\n",
    "        print(arr)\n",
    "        plt.title(titles[i])\n",
    "        plt.pie(arr)\n",
    "        plt.legend(labels=labels, loc=0)\n",
    "\n",
    "\n",
    "def plot_history(ar1, ar2):\n",
    "    plt.plot(ar1)\n",
    "    plt.plot(ar2)\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def convertPreds(y_pred):\n",
    "    res_y_pred = []\n",
    "    for i in range(len(y_pred)):\n",
    "        max_index = y_pred[i].argmax()\n",
    "        res_y_pred.append(max_index)\n",
    "    return res_y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_pie_sets([y_train, y_test])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(channel_size=3):\n",
    "    input_shape = []\n",
    "    if channel_size == 3:  #RGB or HSV channels\n",
    "        input_shape = [IMAGE_WIDTH, IMAGE_HEIGHT, channel_size]\n",
    "    elif channel_size == 1:  #Grayscaled images\n",
    "        input_shape = [IMAGE_WIDTH, IMAGE_HEIGHT, 1]\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', padding=\"same\", input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(256, activation=\"relu\", activity_regularizer=l1_l2()),\n",
    "        Dropout(0.4),\n",
    "        Dense(4, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strafied_kfold(model, X_train, y_train):\n",
    "    # Define a StratifiedKFold object\n",
    "    skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=SEED)\n",
    "    acc = []\n",
    "    val_acc = []\n",
    "    # Iterate over the K folds\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        # Split the data into K folds\n",
    "        X_fold_train, X_fold_val = X_train[train_index], X_train[test_index]\n",
    "        y_fold_train, y_fold_val = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        # Train and evaluate the model on the fold\n",
    "        history = model.fit(X_fold_train, y_fold_train, validation_data=(X_fold_val, y_fold_val), epochs=4)\n",
    "        score = model.evaluate(X_test, y_test, verbose=2)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        acc = np.concatenate((acc, history.history['accuracy']), axis=None)\n",
    "        val_acc = np.concatenate((val_acc, history.history['val_accuracy']), axis=None)\n",
    "    return model, acc, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model, acc, val_acc = strafied_kfold(model, X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_history(acc, val_acc)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
