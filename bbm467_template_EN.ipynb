{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effects of different preprocessing techniques on cataract dataset\n",
    "\n",
    "#### Bekir Semih Tekeli\n",
    "#### Ayşe Şule Bakal\n",
    "\n",
    "Abstract of the project comes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "[Problem](#problem)   \n",
    "[Data Understanding](#data_understanding)   \n",
    "[Data Preparation](#data_preparation)   \n",
    "[Modeling](#modeling)   \n",
    "[Evaluation](#evaluation)   \n",
    "[References](#references)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem <a class=\"anchor\" id=\"problem\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the problem here. What are the questions you are trying to solve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding<a class=\"anchor\" id=\"data_understanding\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span class=\"label label-primary\">Eye Diseases:</span></h1>\n",
    "<div class=\"card text-white bg-info mb-3\" style=\"max-width: 60rem;\">\n",
    "  <div class=\"card-body\">\n",
    "\n",
    "There are many eye diseases. Every anatomical part of this organ can present a disorder and cause an eye disorder. It is important for the patient to fully understand the nature of his ocular disorder in order to take good care of his visual condition. It also makes it possible to better manage a disease and detect signs indicating deterioration. An informed and savvy patient is more likely to be treated on time, to feel confident and to adhere to their treatment..\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div class=\"card text-white bg-primary\" style=\"max-width: 60rem;\">\n",
    "  <div class=\"card-body\">\n",
    "    <p class=\"card-text\">\n",
    "In this dataset, annotations were added by human readers trained in quality control management. They classify patients into four categories, including:\n",
    "\n",
    "</p>\n",
    "  </div>\n",
    "\n",
    " <ul style=\"list-style-type:circle;\">\n",
    "  <li>Normal       (N)</li>\n",
    "  <li>Cataract     (C)</li>\n",
    "  <li>Glaucoma     (G)</li>\n",
    "  <li>Diabetes     (D)</li>\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retina\n",
    "\n",
    "The retina is a delicate, multilayered light-sensitive membrane lining the inside wall at the back of the eye. It is connected by the optic nerve to the brain. The macula, at the center of the retina, creates our ability to see detail. The central pit in the macula that produces the sharpest vision is the fovea. Surrounding the macula is the peripheral retina, which enables our peripheral vision. Attached to the retina, the vitreous is a gel-like substance that fills the eyeball between the lens and the retina.\n",
    "\n",
    "\n",
    "# Normal (N)\n",
    "\n",
    "![](https://www.rcseattle.com/wp-content/uploads/2016/05/resources-normal-1.png)\n",
    "\n",
    "# Cataract (C)\n",
    "A cataract is a clouding of the natural lens of the eye, called the lens. The latter is located inside the eye, behind the iris, which represents the colored part forming the pupil. The diagram of the anatomy of the eye shows it well. Several factors, including age, heredity, medication and environment, contribute to the formation of cataracts. Over time, the lens becomes frosty, yellowish and hazy. The light passing through this lens is therefore altered and diminished by the cataract. Cataract extraction is an intraocular surgical procedure that can permanently treat this condition.\n",
    "\n",
    "![](https://www.nvisioncenters.com/wp-content/uploads/cataract-eye-vs-normal-eye-960x639.jpg)\n",
    "\n",
    "# Glaucoma (G)\n",
    "Glaucoma is an eye disease that irreversibly and permanently affects the optic nerve (structural damage). The optic nerve is the part of the eye through which passes all the visual information captured by the eye. This information travels through the optic nerve and is transmitted to the brain.\n",
    "\n",
    "Glaucoma is a very common disease that affects people of all ages. According to sources, it is estimated that up to 10% of the population would be affected. Globally, this represents 65 million people.\n",
    "\n",
    "![](https://www.wolfeeyeclinic.com/filesimages/Glaucoma/GlaucomaEyeDiagram-min.jpg)\n",
    "\n",
    "# Diabetes (D)\n",
    "Diabetes is a very serious disease that can cause problems like blindness, heart disease, kidney failure and amputations. By taking good care of your health through healthy eating, regular exercise and taking your medications, you can control diabetes. Diabetes can also affect the eye, this is called diabetic retinopathy.\n",
    "\n",
    "All people with diabetes should have an eye exam using a photo-screening device or an eye exam with pupil dilation annually. As soon as the disease (diabetic retinopathy) is visible in the eye, an examination with pupil dilation should be performed for follow-up at variable frequency.\n",
    "\n",
    "In some people with diabetic retinopathy, the blood vessels in the retina may swell and leak, while in others, new abnormal blood vessels may form on the surface of the retina. These changes can lead to vision loss or even blindness.\n",
    "\n",
    "![](https://myvision.org/wp-content/uploads/2022/02/diabetic-retinopathy-diagram-664x321.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation<a class=\"anchor\" id=\"data_preparation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('INFO')\n",
    "import cv2\n",
    "import os, glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = r\"./dataset/\"\n",
    "IMAGE_WIDTH = 128\n",
    "IMAGE_HEIGHT = 128\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "dataset_folders = []  # to keep main folder names\n",
    "total = 0\n",
    "print(f\"There are {len(os.listdir(DATASET_PATH))} folder in dataset.\")\n",
    "for path in sorted(os.listdir(DATASET_PATH)):\n",
    "    print(f\"\\t-There are {len(os.listdir(DATASET_PATH + path))} images in {path} folder.\")\n",
    "    total += len(os.listdir(DATASET_PATH + path))  # add element size of the current folder to total variable\n",
    "    dataset_folders.append(DATASET_PATH + path)  # add current folder path to dataset_folders\n",
    "\n",
    "# Create an empty dataframe\n",
    "df = pd.DataFrame(0,\n",
    "                  columns=['paths',\n",
    "                           'class_label'],\n",
    "                  index=range(total))\n",
    "# store each image path in the dataframe\n",
    "# class labels -> 0:Normal 1:Cataract 2:Glaucoma 3:RetinaDisease\n",
    "i = 0\n",
    "for p, path in enumerate(dataset_folders):  # main folders\n",
    "    for sub_path in sorted(os.listdir(path)):  #images\n",
    "        df.iloc[i, 0] = path + \"/\" + sub_path\n",
    "        df.iloc[i, 1] = p\n",
    "        i += 1\n",
    "# Display some examples for the created DataFrame\n",
    "print(df.sample(frac=1, random_state=SEED).head(10))\n",
    "train_df, test_df = train_test_split(df,\n",
    "                                     test_size=0.2,\n",
    "                                     random_state=SEED,\n",
    "                                     stratify=df['class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_paths = [\"./dataset/1_normal/NL_001.png\", \"./dataset/2_cataract/cataract_001.png\",\n",
    "                 \"./dataset/2_glaucoma/Glaucoma_001.png\", \"./dataset/3_retina_disease/Retina_001.png\"]\n",
    "images_array1 = []\n",
    "images_array2 = []\n",
    "\n",
    "\n",
    "def display_examples(images_array1, images_array2, row1, row2, channel=3):\n",
    "    fig = plt.figure(figsize=(15, 9))\n",
    "    plt.title(f\"First row->{row1} Images    Second row->{row2} Images\")\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    for i in range(4):\n",
    "        current_path = example_paths[i]\n",
    "\n",
    "        fig.add_subplot(2, 4, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.title(current_path.split(\"/\")[3])\n",
    "        plt.imshow(images_array1[i])\n",
    "\n",
    "        fig.add_subplot(2, 4, i + 5)\n",
    "        plt.axis('off')\n",
    "        plt.title(current_path.split(\"/\")[3])\n",
    "        if channel == 1:\n",
    "            plt.imshow(images_array2[i], cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(images_array2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial preprocess\n",
    "Our first preprocess is apllied also for all other preprocesses that we used.\n",
    "\n",
    "In this preprocess, we delete unnecessary black areas from the images. Also we resize the images to 256x256 due to huge dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cropping image to avoid from unnecessary black areas\n",
    "def deleteBlackAreas(filename):\n",
    "    image_size = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "    img = cv2.imread(filename)  #read image from file\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # convert to grayscale\n",
    "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)  # turn it into a binary image\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # find contours\n",
    "    if len(contours) != 0:\n",
    "        #find the biggest area\n",
    "        cnt = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        #find the bounding rect\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "        crop = img[y:y + h, x:x + w]  # crop image\n",
    "        crop1 = cv2.cvtColor(cv2.resize(crop, image_size, interpolation=cv2.INTER_AREA),\n",
    "                             cv2.COLOR_BGR2RGB)  # resize to image_size and change color space from BGR to RGB for matplotlib\n",
    "        return crop1\n",
    "    else:\n",
    "        return cv2.cvtColor(cv2.resize(img, image_size, interpolation=cv2.INTER_AREA), cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    img = cv2.resize(cv2.cvtColor(cv2.imread(example_paths[i]), cv2.COLOR_BGR2RGB), (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    images_array1.append(img)\n",
    "    img2 = deleteBlackAreas(example_paths[i])\n",
    "    images_array2.append(img2)\n",
    "display_examples(images_array1, images_array2, \"Normal\", \"Cropped\")\n",
    "images_array1.clear()\n",
    "images_array2.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Normalization of histogram of images\n",
    "In this preprocess, we normalize all three (R-G-B) channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color_normalization of images\n",
    "def color_normalization(img):\n",
    "    image_copy = img.copy()\n",
    "    for i in range(3):\n",
    "        imi = img[:, :, i]\n",
    "        minval = np.min(imi)\n",
    "        maxval = np.max(imi)\n",
    "        imrange = maxval - minval\n",
    "        # imi-minval will turn the color range between 0-imrange, and the scaling will stretch the range between 0-255\n",
    "        image_copy[:, :, i] = (255 / (imrange + 0.0001) * (imi - minval))\n",
    "    return image_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    img = deleteBlackAreas(example_paths[i])\n",
    "    images_array1.append(img)\n",
    "    img2 = color_normalization(img)\n",
    "    images_array2.append(img2)\n",
    "display_examples(images_array1, images_array2, \"Cropped\", \"Normalized\")\n",
    "images_array1.clear()\n",
    "images_array2.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Canny Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge(img):\n",
    "    t_lower = 20\n",
    "    t_upper = 120\n",
    "    edges = cv2.Canny(img, t_lower, t_upper, apertureSize=3, L2gradient=True)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    img = deleteBlackAreas(example_paths[i])\n",
    "    images_array1.append(img)\n",
    "    img2 = canny_edge(img)\n",
    "    images_array2.append(img2)\n",
    "display_examples(images_array1, images_array2, \"Cropped\", \"Canny Edge\", 1)\n",
    "images_array1.clear()\n",
    "images_array2.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.GrayScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToGray(img):\n",
    "    img_copy = img.copy()\n",
    "    img_copy = cv2.cvtColor(img_copy, cv2.COLOR_RGB2GRAY)\n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    img = deleteBlackAreas(example_paths[i])\n",
    "    images_array1.append(img)\n",
    "    img2 = convertToGray(img)\n",
    "    images_array2.append(img2)\n",
    "display_examples(images_array1, images_array2, \"Cropped\", \"Gray Scaled\", 1)\n",
    "images_array1.clear()\n",
    "images_array2.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Histogram Equalization and Adaptive Histogram Equalization\n",
    "Histogram Equalization is a computer image processing technique used to improve contrast in images. It accomplishes this by effectively spreading out the most frequent intensity values, i.e. stretching out the intensity range of the image. This method usually increases the global contrast of images when its usable data is represented by close contrast values. This allows for areas of lower local contrast to gain a higher contrast.\n",
    "Adaptive Histogram Equalization differs from ordinary histogram equalization in the respect that the adaptive method computes several histograms, each corresponding to a distinct section of the image, and uses them to redistribute the lightness values of the image. It is therefore suitable for improving the local contrast and enhancing the definitions of edges in each region of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_equalization(img):\n",
    "    array = np.asarray(img)\n",
    "    bin_cont = np.bincount(array.flatten(), minlength=256)\n",
    "    pixels = np.sum(bin_cont)\n",
    "    bin_cont = bin_cont / pixels\n",
    "    cumulative_sumhist = np.cumsum(bin_cont)\n",
    "    map = np.floor(255 * cumulative_sumhist).astype(np.uint8)\n",
    "    arr_list = list(array.flatten())\n",
    "    eq_arr = [map[p] for p in arr_list]\n",
    "    arr_back = np.reshape(np.asarray(eq_arr), array.shape)\n",
    "    return arr_back\n",
    "\n",
    "\n",
    "def ahe(img, rx=136, ry=185):\n",
    "    img_eq = np.empty((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
    "    for i in range(0, img.shape[1], rx):\n",
    "        for j in range(0, img.shape[0], ry):\n",
    "            t = img[j:j + ry, i:i + rx]\n",
    "            c = hist_equalization(t)\n",
    "            img_eq[j:j + ry, i:i + rx] = c\n",
    "    return img_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    img = deleteBlackAreas(example_paths[i])\n",
    "    images_array1.append(img)\n",
    "    img2 = ahe(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY))\n",
    "    images_array2.append(img2)\n",
    "display_examples(images_array1, images_array2, \"Cropped\", \"AHE\", 1)\n",
    "images_array1.clear()\n",
    "images_array2.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Color Space XYZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertColorSpace(img):\n",
    "    img_copy = cv2.cvtColor(img, cv2.COLOR_RGB2XYZ)\n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    img = deleteBlackAreas(example_paths[i])\n",
    "    images_array1.append(img)\n",
    "    img2 = convertColorSpace(img)\n",
    "    images_array2.append(img2)\n",
    "display_examples(images_array1, images_array2, \"Cropped\", \"XYZ Color Space\")\n",
    "images_array1.clear()\n",
    "images_array2.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarization(img):\n",
    "    img_copy = img.copy()\n",
    "    img_copy = cv2.cvtColor(img_copy, cv2.COLOR_RGB2GRAY)\n",
    "    img_copy = cv2.adaptiveThreshold(img_copy, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 3, 2)\n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    img = deleteBlackAreas(example_paths[i])\n",
    "    images_array1.append(img)\n",
    "    img2 = binarization(img)\n",
    "    images_array2.append(img2)\n",
    "display_examples(images_array1, images_array2, \"Cropped\", \"Binarized\", 1)\n",
    "images_array1.clear()\n",
    "images_array2.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df):\n",
    "    # Creating dataset\n",
    "    images = []\n",
    "    labels = []\n",
    "    index = 0\n",
    "    for path in tqdm(df['paths']):\n",
    "        #According to parameter, we apply some preprocesses here. default=0\n",
    "        img = deleteBlackAreas(path)  #deleting black areas. Initial preprocess\n",
    "        label = [0, 0, 0, 0]\n",
    "        label[df.iloc[index][\"class_label\"]] += 1\n",
    "        index += 1\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "        #Flipping the image horizontally and vertically\n",
    "        imlr = cv2.flip(img, 0)\n",
    "        imud = cv2.flip(img, 1)\n",
    "        #add all the images and labels\n",
    "        images.append(imlr)\n",
    "        labels.append(label)\n",
    "        images.append(imud)\n",
    "        labels.append(label)\n",
    "        if label[0] == 0:  # If the image is not in normal category\n",
    "            # Below processes can be used to increase data size\n",
    "\n",
    "            ## In these processes first we add little brightness to image. Then flip it horizontally and vertically\n",
    "            imb = img + 0.4 * img  # brighter image\n",
    "            imb[imb > 255] = 255\n",
    "            images.append(imb)\n",
    "            labels.append(label)\n",
    "\n",
    "            imblr = cv2.flip(imb, 0)\n",
    "            imbud = cv2.flip(imb, 1)\n",
    "            images.append(imblr)\n",
    "            labels.append(label)\n",
    "            images.append(imbud)\n",
    "            labels.append(label)\n",
    "\n",
    "            ## In these processes first we add little dim to image. Then flip it horizontally and vertically\n",
    "            imd = img - 0.4 * img  #deemer image\n",
    "            imd[imd < 0] = 0\n",
    "            images.append(imd)\n",
    "            labels.append(label)\n",
    "\n",
    "            imdlr = cv2.flip(imd, 0)\n",
    "            imdud = cv2.flip(imd, 1)\n",
    "            images.append(imdlr)\n",
    "            labels.append(label)\n",
    "            images.append(imdud)\n",
    "            labels.append(label)\n",
    "    images = np.array(images, dtype='float32')\n",
    "    labels = np.array(labels)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def changeMode(images, mode):\n",
    "    ret_images = []\n",
    "    for img in images:\n",
    "        if mode == 1:\n",
    "            img = color_normalization(img)\n",
    "        elif mode == 2:\n",
    "            img = np.array(img, dtype=\"uint8\")\n",
    "            img = canny_edge(img)\n",
    "        elif mode == 3:\n",
    "            img = convertToGray(img)\n",
    "        elif mode == 4:\n",
    "            img = np.array(img, dtype=\"uint8\")\n",
    "            img = ahe(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY))\n",
    "        elif mode == 5:\n",
    "            img = convertColorSpace(img)\n",
    "        elif mode == 6:\n",
    "            img = np.array(img, dtype=\"uint8\")\n",
    "            img = binarization(img)\n",
    "        ret_images.append(img)\n",
    "    ret_images = np.array(ret_images, dtype='float32')\n",
    "    return ret_images / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    img = deleteBlackAreas(example_paths[i])\n",
    "    images_array1.append(img)\n",
    "    img2 = img - 0.4 * img  #deemer image\n",
    "    img2[img2 < 0] = 0\n",
    "    images_array2.append(img2 / 255)\n",
    "display_examples(images_array1, images_array2, \"Cropped\", \"Dimmer Cropped\")\n",
    "images_array1.clear()\n",
    "images_array2.clear()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    img = deleteBlackAreas(example_paths[i])\n",
    "    images_array1.append(img)\n",
    "    img2 = img + 0.4 * img  #brighter image\n",
    "    img2[img2 > 255] = 255\n",
    "    images_array2.append(img2 / 255)\n",
    "display_examples(images_array1, images_array2, \"Cropped\", \"Brighter Cropped\")\n",
    "images_array1.clear()\n",
    "images_array2.clear()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling<a class=\"anchor\" id=\"modeling\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we used a model which based on CNN(Convolutional Neural network).\n",
    "Convolutional neural networks (CNNs) are particularly well suited for image classification tasks because they are able to learn hierarchical representations of the data. In image classification, the input is typically an image, which can be thought of as a set of pixel values arranged in a grid. CNNs are able to automatically learn the features present in the images, such as edges, corners, and textures, by applying filters to the input image and creating a transformed output image. These filters are learned during training and are able to extract relevant features from the input data.\n",
    "\n",
    "One of the key advantages of CNNs is that they are able to learn these features directly from the data, without the need for manual feature engineering. This makes them particularly useful for tasks where it is difficult to manually design features that are able to capture the underlying patterns in the data.\n",
    "\n",
    "In addition to being able to learn features directly from the data, CNNs are also able to process images of different sizes and aspect ratios, since the filters are applied over the entire input image. This makes them well suited for tasks where the size and shape of the input images may vary.\n",
    "\n",
    "Overall, CNNs are a powerful tool for image classification tasks and have been successfully applied to a wide range of applications, including object recognition, facial recognition, and medical image analysis.\n",
    "\n",
    "![](https://i.imgur.com/dAvKYes.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(channel_size=3):\n",
    "    input_shape = []\n",
    "    if channel_size == 3:  #RGB or HSV channels\n",
    "        input_shape = [IMAGE_WIDTH, IMAGE_HEIGHT, channel_size]\n",
    "    elif channel_size == 1:  #Grayscaled images\n",
    "        input_shape = [IMAGE_WIDTH, IMAGE_HEIGHT, 1]\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3), activation='relu', padding=\"same\", input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dropout(0.4),\n",
    "        Dense(4, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the model layers\n",
    "model_display = create_model()\n",
    "model_display.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strafied_kfold(model, X_train, y_train):\n",
    "    # Define a StratifiedKFold object\n",
    "    skf = StratifiedKFold(n_splits=9, shuffle=True, random_state=SEED)\n",
    "    acc = []\n",
    "    val_acc = []\n",
    "    test_acc = []\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "    test_loss = []\n",
    "    # Iterate over the K folds\n",
    "    for train_index, test_index in skf.split(X_train, np.argmax(y_train, axis=1)):\n",
    "        # Split the data into K folds\n",
    "        X_fold_train, X_fold_val = X_train[train_index], X_train[test_index]\n",
    "        y_fold_train, y_fold_val = y_train[train_index], y_train[test_index]\n",
    "        # Train and evaluate the model on the fold\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=3, verbose=1)\n",
    "        history = model.fit(X_fold_train, y_fold_train,\n",
    "                            validation_data=(X_fold_val, y_fold_val),\n",
    "                            epochs=6,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            steps_per_epoch=len(X_fold_train) / BATCH_SIZE)\n",
    "        score = model.evaluate(X_test, y_test, verbose=2)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        acc = np.concatenate((acc, history.history['accuracy']), axis=None)\n",
    "        val_acc = np.concatenate((val_acc, history.history['val_accuracy']), axis=None)\n",
    "        loss = np.concatenate((loss, history.history['loss']), axis=None)\n",
    "        val_loss = np.concatenate((val_loss, history.history['val_loss']), axis=None)\n",
    "        test_acc.append(score[1])\n",
    "        test_loss.append(score[0])\n",
    "    return model, acc, val_acc, loss, val_loss, test_acc, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation<a class=\"anchor\" id=\"evaluation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the distribution of data on the train and test\n",
    "def plot_pie_sets(arrays):\n",
    "    titles = [\"Train Set\", \"Test Set\"]\n",
    "    labels = [\"Normal\", \"Cataract\", \"Glaucoma\", \"Retina Disease\"]\n",
    "    fig = plt.figure(figsize=(9, 5))\n",
    "    plt.title(\"Distribution\")\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    for i in range(2):\n",
    "        fig.add_subplot(1, 2, i + 1)\n",
    "        arr = []\n",
    "        for j in range(4):\n",
    "            arr.append((arrays[i] == j).sum())\n",
    "        plt.title(titles[i])\n",
    "        plt.pie(arr)\n",
    "        plt.legend(labels=labels, loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(arrays, title):\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "    plt.title(f\"Evaluation for {title} Images\")\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "\n",
    "    fig.add_subplot(1, 2, 1)\n",
    "    plt.plot(arrays[0])\n",
    "    plt.plot(arrays[1])\n",
    "\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=0)\n",
    "\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    plt.plot(arrays[2])\n",
    "    plt.plot(arrays[3])\n",
    "\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_matrix(model, X_test, y_test, title):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.grid(False)\n",
    "    plt.title(f\"Confusion Matrix of {title}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset and split the data\n",
    "train_images, train_labels = create_dataset(train_df)\n",
    "test_images, test_labels = create_dataset(test_df)\n",
    "labels = [\"Normal\", \"Cataract\", \"Glaucoma\", \"Retina Disease\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_images, train_labels\n",
    "X_test, y_test = test_images, test_labels\n",
    "X_train, X_test = X_train / 255, X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pie_sets([np.argmax(y_train, axis=1), np.argmax(y_test, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model, acc, val_acc, loss, val_loss, test_acc, test_loss = strafied_kfold(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([acc, val_acc, loss, val_loss], \"Just Cropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_matrix(model, X_test, y_test, \"Just Cropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset and split the data\n",
    "X_train = changeMode(train_images, 1)\n",
    "X_test = changeMode(test_images, 1)\n",
    "model = create_model()\n",
    "model, acc, val_acc, loss, val_loss, test_acc_normalized, test_loss_normalized = strafied_kfold(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([acc, val_acc, loss, val_loss], \"Normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_matrix(model, X_test, y_test, \"Normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset and split the data\n",
    "X_train = changeMode(train_images, 2)\n",
    "X_test = changeMode(test_images, 2)\n",
    "model = create_model(1)\n",
    "model, acc, val_acc, loss, val_loss, test_acc_canny_edge, test_loss_canny_edge = strafied_kfold(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([acc, val_acc, loss, val_loss], \"Canny Edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_matrix(model, X_test, y_test, \"Canny Edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset and split the data\n",
    "X_train = changeMode(train_images, 3)\n",
    "X_test = changeMode(test_images, 3)\n",
    "model = create_model(1)\n",
    "model, acc, val_acc, loss, val_loss, test_acc_gray, test_loss_gray = strafied_kfold(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([acc, val_acc, loss, val_loss], \"GrayScaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_matrix(model, X_test, y_test, \"GrayScaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset and split the data\n",
    "X_train = changeMode(train_images, 4)\n",
    "X_test = changeMode(test_images, 4)\n",
    "model = create_model(1)\n",
    "model, acc, val_acc, loss, val_loss, test_acc_ahe, test_loss_ahe = strafied_kfold(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([acc, val_acc, loss, val_loss], \"AHE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_matrix(model, X_test, y_test, \"AHE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset and split the data\n",
    "X_train = changeMode(train_images, 5)\n",
    "X_test = changeMode(test_images, 5)\n",
    "model = create_model()\n",
    "model, acc, val_acc, loss, val_loss, test_acc_xyz, test_loss_xyz = strafied_kfold(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([acc, val_acc, loss, val_loss], \"XYZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_matrix(model, X_test, y_test, \"XYZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset and split the data\n",
    "X_train = changeMode(train_images, 6)\n",
    "X_test = changeMode(test_images, 6)\n",
    "model = create_model(1)\n",
    "model, acc, val_acc, loss, val_loss, test_acc_bin, test_loss_bin = strafied_kfold(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([acc, val_acc, loss, val_loss], \"Binarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_matrix(model, X_test, y_test, \"Binarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_acc)\n",
    "plt.plot(test_acc_normalized)\n",
    "plt.plot(test_acc_canny_edge)\n",
    "plt.plot(test_acc_gray)\n",
    "plt.plot(test_acc_ahe)\n",
    "plt.plot(test_acc_xyz)\n",
    "plt.plot(test_acc_bin)\n",
    "plt.title(\"Test Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.legend([\"Just Cropped\", \"Normalized\", \"Canny Edge\", \"GrayScale\", \"AHE\", \"XYZ\", \"Binarization\"], loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_loss)\n",
    "plt.plot(test_loss_normalized)\n",
    "plt.plot(test_loss_canny_edge)\n",
    "plt.plot(test_loss_gray)\n",
    "plt.plot(test_loss_ahe)\n",
    "plt.plot(test_loss_xyz)\n",
    "plt.plot(test_loss_bin)\n",
    "plt.title(\"Test Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.legend([\"Just Cropped\", \"Normalized\", \"Canny Edge\", \"GrayScale\", \"AHE\", \"XYZ\", \"Binarization\"], loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Disclaimer!** <font color='grey'>This notebook was prepared by <student name(s)> as a term project for the *BBM467 - Data Intensive Applications* class. The notebook is available for educational purposes only. There is no guarantee on the correctness of the content provided as it is a student work.\n",
    "\n",
    "If you think there is any copyright violation, please let us [know](https://forms.gle/BNNRB2kR8ZHVEREq8). \n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
